<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="UTF-8"><meta name="copyright" content="(C) Copyright 2015">
<meta name="DC.rights.owner" content="(C) Copyright 2015">
<meta name="DC.Type" content="topic">
<meta name="description" content="Data recovery from remote clusters requires an XDCR environment and adequate amount of memory and disk space to support the workload and recovered data."><meta name="DC.Relation" scheme="URI" content="../Tasks/tasks-manage-xdcr.html">
<meta name="DC.Relation" scheme="URI" content="../Tasks/xdcr-modify-settings.html">
<meta name="DC.Relation" scheme="URI" content="../XDCR/xdcr-memory-replication.html">
<meta name="DC.Relation" scheme="URI" content="tasks-nodeFailover.html">
<meta name="DC.Relation" scheme="URI" content="../XDCR/xdcr-intro.html">
<meta name="DC.Relation" scheme="URI" content="tasks-manage-xdcr.html">
<meta name="DC.Relation" scheme="URI" content="tasks-rebalance.html">
<meta name="DC.Format" content="XHTML">
<meta name="DC.Identifier" content="topic8798">
<meta name="DC.Language" content="en-us">
<link rel="stylesheet" type="text/css" href="../commonltr.css">
<title>Data recovery from remote clusters</title>
</head>
<body id="topic8798">


 <h1 class="title topictitle1">Data recovery from remote clusters</h1>

 
 <div class="body"><p class="shortdesc">Data recovery from remote clusters requires an XDCR environment and 
  adequate amount of memory and disk space to support the workload and recovered data.</p>

  <p class="p">If more nodes fail in a cluster than the number of replicas, data partitions in that cluster
   will no longer be available. For instance, if you have a four node cluster with one replica per
   node and two nodes fail, some data partitions will no longer be available. There are two
   solutions for this scenario:</p>

  <ul class="ul">
   <li class="li">Recover data from disk. If you plan on recovering from disk, you may not be able to do so
     if the disk completely fails.</li>

   <li class="li">Recover partitions from a remote cluster. You can use this second option when you have
     XDCR set up to replicate data to the second cluster. The requirement for using
      <samp class="ph codeph">cbrecovery</samp> is that you need to set up a second cluster that will contain
     backup data.</li>

  </ul>

  <p class="p">The following shows a scenario where replica vBuckets are lost from a
   cluster due to multi-node failure:</p>

  
  <img class="image" src="../images/cb_rec_multi_failure.png" width="600">
  
  <p class="p">Before you perform a recovery, make sure that your main cluster has an adequate amount of
   memory and disk space to support the workload as well as the data you recover. This means that
   even though you can recover data to a cluster with failed nodes, you should investigate what
   caused the node failures and also make sure your cluster has adequate capacity before you recover
   data. If you do add nodes be certain to rebalance only after you have </p>

  
  <p class="p">When you use <samp class="ph codeph">cbrecovery</samp> it compares the data partitions from a main cluster
   with a backup cluster, then sends missing data partitions detected. If it fails, once you
   successfully restart <samp class="ph codeph">cbrecovery</samp>, it will do a delta between clusters again and
   determine any missing partitions since the failure then resume restoring these partitions.</p>

  <p class="p"><strong class="ph b">Failure Scenarios</strong></p>

  <p class="p">Imagine the following happens when you have a four node cluster with one replica. Each node has
   256 active and 256 replica vBuckets which total 1024 active and 1024 replica vBuckets:</p>

  <ol class="ol">
   <li class="li">When one node fails, some active and some replica vBuckets are no longer available in the
     cluster.</li>

   <li class="li">After you fail over this node, the corresponding replica vBuckets on other nodes will be
     put into an active state. At this point you have a full set of active vBuckets and a partial
     set of replica vBuckets in the cluster.</li>

   <li class="li">A second node fails. More active vBuckets will not be accessible.</li>

   <li class="li">You fail over the second node. At this point any missing active vBuckets that do not have
     corresponding replica vBuckets will be lost.</li>

  </ol>

  <p class="p">In this type of scenario you can use <samp class="ph codeph">cbrecovery</samp> to get the missing vBuckets
   from your backup cluster. If you have multi-node failure on both your main and backup clusters
   you will experience data loss.</p>

  <p class="p"><strong class="ph b">Recovery Scenarios for cbrecovery</strong></p>

  <p class="p">The following describes some different cluster setups so that you can better understand whether
   or not this approach will work in your failure scenario:</p>

  <ul class="ul">
   <li class="li">Multiple Node Failure in Cluster. If multiple nodes fail in a cluster then some
     vBuckets may be unavailable. In this case if you have already setup XDCR with another cluster,
     you can recover those unavailable vBuckets from the other cluster.</li>

   <li class="li">Bucket with Inadequate Replicas.</li>

  </ul>

  <p class="p"><strong class="ph b">Single Bucket</strong>. In this case where we have only one bucket with zero replicas on all the
   nodes in a cluster. In this case when a node goes down in the cluster some of the partitions for
   that node will be unavailable. If we have XDCR set up for this cluster we can recover the missing
   partitions with <samp class="ph codeph">cbrecovery</samp>.</p>

  <p class="p"><strong class="ph b">Multi-Bucket</strong>. In this case, nodes in a cluster have multiple buckets and some buckets
   might have replicas and some do not. In the image below we have a cluster and all nodes have two
   buckets, Bucket1 and Bucket2. Bucket 1 has replicas but Bucket2 does not. In this case if one of
   the nodes goes down, since Bucket 1 has replicas, when we failover the node the replicas on other
   nodes will be activated. But for the bucket with no replicas some partitions will be unavailable
   and will require <samp class="ph codeph">cbrecovery</samp> to recover data. In this same example if multiple
   nodes fail in the cluster, we need to perform vBucket recovery both buckets since both will have
   missing partitions.</p>

  
  <img class="image" src="../images/cbrecovery_diff_replicas.png" width="600">
  
  <p class="p"><strong class="ph b">Handling the Recovery</strong></p>

  <p class="p">Should you encounter node failure and have unavailable vBuckets, you should follow this
   process:</p>

  <ol class="ol">
   <li class="li">For each failed node, Click Fail Over under the Server Nodes tab in Web Console. 
    <p class="p">After you click Fail Over, under Web Console | Log tab you will see whether data is
     unavailable and which vBuckets are unavailable. If you do not have enough replicas for the
     number of failed over nodes, some vBuckets will no longer be available:</p>


      <img class="image" src="../images/post-failover-log-lost-data.png" width="600">
   </li>


   <li class="li">Add new functioning nodes to replace the failed nodes.
    <p class="p">Do not rebalance after you add new nodes to the cluster. Typically you do this after adding
     nodes to a cluster, but in this scenario the rebalance will destroy information about the
     missing vBuckets and you cannot recover them.</p>


      <img class="image" src="../images/cb_recovery1b.png" width="600">

    <p class="p">In this example we have two nodes that failed in a three-node cluster and we add a new node
     10.3.3.61.</p>

    <p class="p">If you are certain your cluster can easily handle the workload and recovered data, you may
     choose to skip this step.</p>
</li>

   
   <li class="li">Run <samp class="ph codeph">cbrecovery</samp> to recover data from your backup cluster. In the Server
     Panel, a Stop Recovery button appears.

      <img class="image" src="../images/cb_recovery2.png" width="600">
    <p class="p">After the recovery completes, this button disappears.</p>

   </li>

    
   <li class="li">Rebalance your cluster.
    <p class="p">Once the recovery is done, you can rebalance your cluster, which will recreate replica
     vBuckets and evenly redistribute them across the cluster.</p>


      <img class="image" src="../images/cbrecovery_3b.png" width="600">
   </li>

  </ol>

  
  <p class="p"><strong class="ph b">Recovery ‘Dry-Run’</strong></p>

  <p class="p">Before you recover vBuckets, you may want to preview a list of buckets no longer available in
   the cluster. Use this command and options:</p>

  <pre class="pre codeblock">
   shell&gt; ./cbrecovery http://Administrator:password@10.3.3.72:8091 http://Administrator:password@10.3.3.61:8091 -n
</pre>

  <p class="p">Here we provide administrative credentials for the node in the cluster as well as the option
    <samp class="ph codeph">-n</samp>. This will return a list of vBuckets in the remote secondary cluster which
   are no longer in the your first cluster. If there are any unavailable buckets in the cluster with
   failed nodes, you see output as follows:</p>

  <pre class="pre codeblock">
   2013-04-29 18:16:54,384: MainThread Missing vbuckets to be recovered:[{"node": "ns_1@10.3.3.61",
"vbuckets": [513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,, 528, 529,
530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,, 547, 548,
549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,
568, 569, 570, 571, 572,....
</pre>

  <p class="p">Where the <samp class="ph codeph">vbuckets</samp> array contains all the vBuckets that are no longer
   available in the cluster. These are the bucket you can recover from the remotes cluster. To
   recover the vBuckets:</p>

  <pre class="pre codeblock">
shell&gt; ./cbrecovery http://Administrator:password@&lt;From_IP&gt;:8091 \
 http://Administrator:password@&lt;To_IP&gt;:8091 -B bucket_name
</pre>

  <p class="p">You can run the command on either the cluster with unavailable vBuckets or on the remote
   cluster, as long as you provide the hostname, port, and credentials for remote cluster and the
   cluster with missing vBuckets in that order. If you do not provide the parameter
    <samp class="ph codeph">-B</samp> the tool assumes you will recover unavailable vBuckets for the default
   bucket.</p>

  <p class="p"><strong class="ph b">Monitoring the Recovery Process</strong></p>

  <p class="p">You can monitor the progress of recovery under the Data Buckets tab of Couchbase Web
   Console:</p>

  <ol class="ol">
   <li class="li">Click on the Data Buckets tab.</li>

   <li class="li">Select the data bucket you are recovering in the Data Buckets drop-down.</li>

   <li class="li">Click on the Summary drop-down to see more details about this data bucket. You see an
     increased number in the <samp class="ph codeph">items</samp> level during recovery:

      <img class="image" src="../images/monitor_cb_recovery.png" width="600">
   </li>


   <li class="li">You can also see the number of active vBuckets increase as they are recovered until you
     reach 1024 vBuckets. Click on the vBucket Resources drop-down:

      <img class="image" src="../images/cbrec_monitor_vbucks.png" width="600">

   <p class="p">As this tool runs from the command line you can stop it at any time as you would any other
     command-line tool.</p>

   </li>

    <li class="li">A <samp class="ph codeph">Stop Recovery</samp> button appears in the Servers panels. If you click this
     button, you will stop the recovery process between clusters. Once the recovery process
     completes, this button will no longer appear and you will need to rebalance the cluster. If you
     are in Couchbase Web Console, you can also stop it in this panel:

      <img class="image" src="../images/stop_cbrecovery.png" width="600">
    </li>


   <li class="li">After recovery completes, click on the Server Nodes tab then Rebalance to rebalance your
     cluster.</li>

  </ol>

  
  
  <p class="p">When <samp class="ph codeph">cbrecovery</samp> finishes it will output a report in the console:</p>

  <pre class="pre codeblock">
 Recovery :                Total |    Per sec
 batch    :                 0000 |       14.5
 byte     :                 0000 |      156.0
 msg      :                 0000 |       15.6
4 vbuckets recovered with elapsed time 10.90 seconds
</pre>

  
  <p class="p">In this report <samp class="ph codeph">batch</samp> is a group of internal operations performed by
    <samp class="ph codeph">cbrecovery</samp>, <samp class="ph codeph">byte</samp> indicates the total number of bytes recovered
   and <samp class="ph codeph">msg</samp> is the number of documents recovered.</p>

 </div>

 <nav class="related-links">
<div class="familylinks">
<div class="parentlink"><strong>Parent topic:</strong> <a class="link" href="../Tasks/tasks-manage-xdcr.html" title="Cross datacenter replication (XDCR) provides an easy method of replicating data from one cluster to another for disaster recovery as well as better data locality (getting data closer to its users).">Managing XDCR</a></div>
<div class="previouslink"><strong>Previous topic:</strong> <a class="link" href="../Tasks/xdcr-modify-settings.html" title="To modify XDCR advanced settings, use either the Couchbase Server CLI or REST API.">Modifying XDCR settings</a></div>
<div class="nextlink"><strong>Next topic:</strong> <a class="link" href="../XDCR/xdcr-memory-replication.html" title="Stream-based XDCR collects data changes from memory on the source cluster and streams the data changes directly to memory on the destination cluster.">Stream-based XDCR</a></div>
</div>

<div class="linklist linklist">
<div><a class="link" href="tasks-nodeFailover.html" title="Failing over a node means that Couchbase Server removes the node from a cluster and makes replicated data at other nodes available for client requests.">Failover considerations</a></div>
<div><a class="link" href="../XDCR/xdcr-intro.html" title="XDCRは、主に災害復旧のために、あるクラスタのデータを別のクラスタに複製します。">クロスデータセンターレプリケーション（XDCR）</a></div>
<div><a class="link" href="tasks-manage-xdcr.html" title="Cross datacenter replication (XDCR) provides an easy method of replicating data from one cluster to another for disaster recovery as well as better data locality (getting data closer to its users).">Managing XDCR</a></div>
<div><a class="link" href="tasks-rebalance.html" title="Rebalancing is the process of redistributing information across nodes.">Rebalancing</a></div></div>
</nav>

</body>
</html>